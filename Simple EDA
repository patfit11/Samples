# first clear the memory
rm(list = ls())


#### Goal
# Suppose that you are getting this data in order to build a predictive model for mpg (miles per gallon). 
# Using the full dataset, investigate the data using exploratory data analysis such as scatterplots, and other tools.
# Pre-process this data and justify your choices.

# load the package
library("ISLR")

# take a quick look at our data
head(Auto)
names(Auto)

# take a look at all the data for any obvious correlation
pairs(Auto)

# start out by just looking at mpg
quartz()
par(mfrow=c(1,3))
hist(Auto$mpg)
boxplot(Auto$mpg, horizontal=TRUE, main="mpg")
plot(mpg~year, data=Auto, col=Auto$origin)
# looks like as time goes on, mpg steadily increases

# compare mpg by country of origin
quartz()
stripplot(origin~mpg, xlab="mpg by country", data=Auto)
# American made cars have noticeably lower mpg and a wider spread than either European or Japanese made cars
# confirmed by the density plot
quartz()
densityplot(~mpg | origin, data=Auto, auto.key=list(space="right"))


# start by looking at each quantitative variable and its effect on mpg
quartz()
par(mfrow=c(1,7))
plot(mpg ~ cylinders, data=Auto, main="Effect of Cylinders", pch=16)
plot(mpg ~ displacement, data=Auto, main="Effect of Engine Size", pch=16)
plot(mpg ~ horsepower, data=Auto, main="Effect of Horsepower", pch=16)
plot(mpg ~ weight, data=Auto, main="Effect of Car's Weight", pch=16)
plot(mpg ~ acceleration, data=Auto, main="Car's Acceleration", pch=16)
plot(mpg ~ year, data=Auto, main="Year Car was Built", pch=16)
plot(mpg ~ origin, data=Auto, main="Country of Origin", pch=16)

# take a closer look now at displacement, horsepower, weight, and acceleration
quartz()
par(mfrow=c(1,4))
plot(mpg ~ displacement, data=Auto, main="Effect of Engine Size", pch=16)
plot(mpg ~ horsepower, data=Auto, main="Effect of Horsepower", pch=16)
plot(mpg ~ weight, data=Auto, main="Effect of Car's Weight", pch=16)
plot(mpg ~ acceleration, data=Auto, main="Car's Acceleration", pch=16)

# displacement, horsepower, and weight seem to follow a similar pattern
# add a smooth curve and account for country of origin
quartz()
par(mfrow=c(1,3))
plot(mpg ~ displacement, data=Auto, main="Effect of Engine Size", pch=16, col=Auto$origin)
with(Auto, lines(lowess(displacement, mpg), lines=2))
plot(mpg ~ horsepower, data=Auto, main="Effect of Horsepower", pch=16, col=Auto$origin)
with(Auto, lines(lowess(horsepower, mpg), lines=2))
plot(mpg ~ weight, data=Auto, main="Effect of Car's Weight", pch=16, col=Auto$origin)
with(Auto, lines(lowess(weight, mpg), lines=2))
# can see distinct differences between the three chosen variables more clearly now
# consistently seeing that American cars have lower mpg, larger engines, more horsepower, and are the heaviest
  # would naturally assume that this factors into American cars having lower mpg than competitors
  # heavy cars with large engines and more horsepower will likely be less fuel efficient


# look at some boxplots to identify outliers
quartz()
par(mfrow=c(1,4))
boxplot(Auto$displacement, horizontal=TRUE, main="Engine Displacement")
boxplot(Auto$horsepower, horizontal=TRUE, main="Horsepower")
boxplot(Auto$weight, horizontal=TRUE, main="Car Weight")
boxplot(Auto$acceleration, horizontal=TRUE, main="0-60")
# see outliers in horsepower and acceleration
quartz()
par(mfrow=c(1,2))
boxplot(Auto$horsepower, horizontal=TRUE, main="Horsepower")
boxplot(Auto$acceleration, horizontal=TRUE, main="0-60")

# remove name from list of variables
auto <- Auto[,-9]
names(auto)

# further investigate correlation between variables seen previously
quartz()
par(mfrow=c(2,3))
plot(displacement~horsepower, data=Auto) # strong
plot(displacement~acceleration, data=Auto) # no correlation
plot(displacement~weight, data=Auto) # strong
plot(horsepower~acceleration, data=Auto) # moderate
plot(horsepower~weight, data=Auto) # strong
plot(acceleration~weight, data=Auto) # no correlation






# Next, perform a multiple regression on the dataset you pre-processed in question one using the lm() function. 
# The response variable is mpg.
library("leaps")

# start by looking at a model containing all of the variables
large_model <- lm(mpg ~., data=auto)
summary(large_model)
# see cylinders, horsepower, and acceleration can all be removed at the 0.05 level

# trim the large model
trim_large_model <- lm(mpg~.-cylinders -horsepower -acceleration, data=auto)
summary(trim_large_model)
# see a slight drop in adjusted r-squared and that displacement can also be dropped

# trim the model again
trim_again_large_model <- lm(mpg~.-cylinders -horsepower -acceleration -displacement, data=auto)
summary(trim_again_large_model)
# little to no change in adjusted r-squared and all variables are significant at the 0.05 level now
  # expected to see these variables removed, logically, since they would all contribute to a lower mpg

# best single model based on number of beta-terms specified
regfit.full_one <- regsubsets(mpg ~ ., data=auto, nvmax=8, method="exhaustive", really.big=T)
my_sum <- summary(regfit.full_one)
my_sum
# top two models based on number of beta-terms specified
regfit.full_two <- regsubsets(mpg ~ ., data=auto, nbest=2, nvmax=8, method="exhaustive", really.big=T)
summary(regfit.full_two)

# plot the results to visualize what we calculated
quartz()
par(mfrow=c(2,2))
plot(my_sum$rss, xlab="Number of Variables", ylab="RSS", type="l")
plot(my_sum$adjr2, xlab="Number of Variables", ylab="Adjusted R^2", type="l")
plot(my_sum$cp, xlab="Number of Variables", ylab="Cp", type="l")
plot(my_sum$bic, xlab="Number of Variables", ylab="BIC", type="l")
# can see that the model with 3 terms is ~the best option available
  # this is confirmed between the linear models I manually fit and the regsubsets performed
    # can see that the model that includes weight, year, and origin is the best predictor for mpg


# now want to look deeper into the country of origin and how that affects things
  # start by creating new variables "American", "European", and "Japanese"
auto$American <- NA
auto$American[auto$origin=="1"] <- "1"
auto$American[auto$origin=="2"] <- "0"
auto$American[auto$origin=="3"] <- "0"
auto$European <- NA
auto$European[auto$origin=="2"] <- "1"
auto$European[auto$origin=="1"] <- "0"
auto$European[auto$origin=="3"] <- "0"
auto$Japanese <- NA
auto$Japanese[auto$origin=="3"] <- "1"
auto$Japanese[auto$origin=="1"] <- "0"
auto$Japanese[auto$origin=="2"] <- "0"

# remove origin
new_auto <- auto[,-8]


# perform analysis again
new_model <- lm(mpg~., data=new_auto)
summary(new_model)

# create some (educated) interactions between variables
int_model_am_one <- lm(mpg~displacement+displacement*American+weight+year, data=new_auto)
summary(int_model_am_one)
int_model_am_two <- lm(mpg~displacement+weight+weight*American+year, data=new_auto)
summary(int_model_am_two)
# saw from the summary that displacement is not significant at the 0.05 level int he last model
two_two <- lm(mpg~weight+weight*American+year, data=new_auto)
summary(two_two)

int_model_am_three <- lm(mpg~displacement+weight+year+year*American, data=new_auto)
summary(int_model_am_three)


# look at the 
# best single model based on number of beta-terms specified
regfit.full_one <- regsubsets(mpg ~ displacement+displacement*American+weight+weight*American+year+year*American, data=new_auto, method="exhaustive", really.big=T)
my_sum_two <- summary(regfit.full_one)
my_sum_two


# plot the results to visualize what we calculated
quartz()
par(mfrow=c(2,2))
plot(my_sum_two$rss, xlab="Number of Variables", ylab="RSS", type="l")
plot(my_sum_two$adjr2, xlab="Number of Variables", ylab="Adjusted R^2", type="l")
plot(my_sum_two$cp, xlab="Number of Variables", ylab="Cp", type="l")
plot(my_sum_two$bic, xlab="Number of Variables", ylab="BIC", type="l")
# can see visually that the model with 5 terms is approximately the best fit for the data
  # interstingly, displacement is not included
  # two interaction terms (weight*American and year*American) are included
    # saw previously that all cars performed better over time and this data tells a similar story





